import{ENCODER as d,DECODER as i}from"../../globs/shared.js";import{ChatParser as O,TokenParser as h}from"./transforms.js";import{createParser as A}from"eventsource-parser";import{pipeline as m,yieldStream as u}from"yield-stream";import{yieldStream as k}from"yield-stream/node";import{OpenAIError as I}from"../errors.js";const c=(e,{mode:o="tokens",onDone:s})=>new ReadableStream({async start(r){const S=A(async n=>{if(n.type==="event"){const{data:a}=n;if(a==="[DONE]"){r.desiredSize===null||r.close(),await s?.();return}try{const t=JSON.parse(a);if(r.enqueue(d.encode(a)),o==="tokens"&&t?.choices){const{choices:l}=t;for(const y of l)if(y?.finish_reason==="length")throw new I("MAX_TOKENS")}}catch(t){r.error(t)}}}),f=typeof e.pipe=="function";for await(const n of f?k(e):u(e)){const a=i.decode(n);try{const t=JSON.parse(a);t.hasOwnProperty("error")&&r.error(new Error(t.error.message))}catch{}S.feed(a)}}}),p=({onParse:e})=>async function*(s){const r=i.decode(s);e?.(r),r&&(yield d.encode(r))},x=(e,o={mode:"tokens"})=>m(c(e,o),h,p(o)),v=(e,o={mode:"tokens"})=>m(c(e,o),O,p(o));export{v as ChatStream,c as EventStream,x as TokenStream};
